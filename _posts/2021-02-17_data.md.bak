---
layout: post
title:  "Welcome to xieyi's"
date:   2021-02-17 20:00:32
categories: ML
---

# 一、数据处理
1.数据读入

2.数据转化（分类型变量）

3.数据基本展示

4.数据清洗（删除、缺失值）

5.数据划分（归一化）

以预测回归问题+神经网络+Pytorch为例，说明一个完整的机器学习过程。

数据集来源于网络，代码整理自2021.02.05朱老师课堂内容

## 1、数据读入


```python
import pandas as pd
```


```python
df = pd.read_csv('diamonds.csv',index_col=0) # index_col=0 不读入csv中的序列
print(f'前5行数据\n{df.head()}')
print(f'每列的基本信息\n{df.info()}')
```

    前5行数据
       carat      cut color clarity  depth  table  price     x     y     z
    1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43
    2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31
    3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31
    4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63
    5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75
    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 53940 entries, 1 to 53940
    Data columns (total 10 columns):
    carat      53940 non-null float64
    cut        53940 non-null object
    color      53940 non-null object
    clarity    53940 non-null object
    depth      53940 non-null float64
    table      53940 non-null float64
    price      53940 non-null int64
    x          53940 non-null float64
    y          53940 non-null float64
    z          53940 non-null float64
    dtypes: float64(6), int64(1), object(3)
    memory usage: 4.5+ MB
    每列的基本信息
    None
    

## 2.数据转化（分类型变量）

cut color clarity为分类型变量，通过labelEncoder转化


```python
print(f'cut 因子出现的水平数{df["cut"].nunique()}')
print(f'cut 因子出现的水平{df["cut"].unique()}')
df2 = df.copy() # 在复制的表上修改
```

    cut 因子出现的水平数5
    cut 因子出现的水平['Ideal' 'Premium' 'Good' 'Very Good' 'Fair']
    

各个水平之间有顺序关系


```python
from pandas.api.types import CategoricalDtype
```


```python
cutCateg = CategoricalDtype(['Ideal', 'Premium', 'Good', 'Very Good', 'Fair'],ordered=True)
df2['cut'] = df['cut'].astype(cutCateg)
print(f'cut转化后 因子出现的水平{df2["cut"].unique()}')
```

    cut转化后 因子出现的水平[Ideal, Premium, Good, Very Good, Fair]
    Categories (5, object): [Ideal < Premium < Good < Very Good < Fair]
    


```python
print(f'color 因子出现的水平数{df["color"].nunique()}')
print(f'color 因子出现的水平{df["color"].unique()}')
```

    color 因子出现的水平数7
    color 因子出现的水平['E' 'I' 'J' 'H' 'F' 'G' 'D']
    


```python
colorCateg = CategoricalDtype(['D','E','F','G','H','I','J'],ordered=True)
df2['color'] = df['color'].astype(colorCateg)
print(f'color转化后 因子出现的水平{df2["color"].unique()}')
```

    color转化后 因子出现的水平[E, I, J, H, F, G, D]
    Categories (7, object): [D < E < F < G < H < I < J]
    


```python
print(f'clarity 因子出现的水平数{df["clarity"].nunique()}')
print(f'clarity 因子出现的水平{df["clarity"].unique()}')
```

    clarity 因子出现的水平数8
    clarity 因子出现的水平['SI2' 'SI1' 'VS1' 'VS2' 'VVS2' 'VVS1' 'I1' 'IF']
    


```python
clarityCateg = CategoricalDtype(['IF','VVS1','VVS2','VS1','VS2','SI1','SI2','I1'],ordered=True)
df2['clarity'] = df['clarity'].astype(clarityCateg)
print(f'clarity 因子出现的水平{df2["clarity"].unique()}')
```

    clarity 因子出现的水平[SI2, SI1, VS1, VS2, VVS2, VVS1, I1, IF]
    Categories (8, object): [IF < VVS1 < VVS2 < VS1 < VS2 < SI1 < SI2 < I1]
    

## 3.数据基本展示

分类型变量的列，不同因子取值的样本数


```python
print(f'cut:\n{df2["cut"].value_counts(dropna=False)}')
print(f'color:\n{df2["color"].value_counts(dropna=False)}')
print(f'clarity:\n{df2["clarity"].value_counts(dropna=False)}')
```

    cut:
    Ideal        21551
    Premium      13791
    Very Good    12082
    Good          4906
    Fair          1610
    Name: cut, dtype: int64
    color:
    G    11292
    E     9797
    F     9542
    H     8304
    D     6775
    I     5422
    J     2808
    Name: color, dtype: int64
    clarity:
    SI1     13065
    VS2     12258
    SI2      9194
    VS1      8171
    VVS2     5066
    VVS1     3655
    IF       1790
    I1        741
    Name: clarity, dtype: int64
    


```python
import matplotlib.pyplot as plt
%matplotlib inline
```


```python
df2['price'].hist(bins=10)# 分成10个桶，0~2500的价格的钻石有约25000个
df2['price'].hist(bins=20)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x2769caf7b38>




![png](output_18_1.png)



```python
df2['price'].hist(bins=20,by=df2['cut'])
```




    array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000002769CB473C8>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x000002769D54F4A8>],
           [<matplotlib.axes._subplots.AxesSubplot object at 0x000002769D57FA58>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x000002769D5BF048>],
           [<matplotlib.axes._subplots.AxesSubplot object at 0x000002769D5EE5F8>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x000002769D621BA8>]],
          dtype=object)




![png](output_19_1.png)



```python
# 数值型变量的相关性
df2.corr()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>carat</th>
      <th>depth</th>
      <th>table</th>
      <th>price</th>
      <th>x</th>
      <th>y</th>
      <th>z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>carat</th>
      <td>1.000000</td>
      <td>0.028224</td>
      <td>0.181618</td>
      <td>0.921591</td>
      <td>0.975094</td>
      <td>0.951722</td>
      <td>0.953387</td>
    </tr>
    <tr>
      <th>depth</th>
      <td>0.028224</td>
      <td>1.000000</td>
      <td>-0.295779</td>
      <td>-0.010647</td>
      <td>-0.025289</td>
      <td>-0.029341</td>
      <td>0.094924</td>
    </tr>
    <tr>
      <th>table</th>
      <td>0.181618</td>
      <td>-0.295779</td>
      <td>1.000000</td>
      <td>0.127134</td>
      <td>0.195344</td>
      <td>0.183760</td>
      <td>0.150929</td>
    </tr>
    <tr>
      <th>price</th>
      <td>0.921591</td>
      <td>-0.010647</td>
      <td>0.127134</td>
      <td>1.000000</td>
      <td>0.884435</td>
      <td>0.865421</td>
      <td>0.861249</td>
    </tr>
    <tr>
      <th>x</th>
      <td>0.975094</td>
      <td>-0.025289</td>
      <td>0.195344</td>
      <td>0.884435</td>
      <td>1.000000</td>
      <td>0.974701</td>
      <td>0.970772</td>
    </tr>
    <tr>
      <th>y</th>
      <td>0.951722</td>
      <td>-0.029341</td>
      <td>0.183760</td>
      <td>0.865421</td>
      <td>0.974701</td>
      <td>1.000000</td>
      <td>0.952006</td>
    </tr>
    <tr>
      <th>z</th>
      <td>0.953387</td>
      <td>0.094924</td>
      <td>0.150929</td>
      <td>0.861249</td>
      <td>0.970772</td>
      <td>0.952006</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



## 4.数据清洗（删除、缺失值）

用堆积条形图绘制缺失值比例


```python
x = list(df2.columns)
rows = df2.shape[0]
y1 = df2.isna().sum() # 统计缺失值
y1 = [i/rows for i in y1] # 转换为比例
y2 = [1-i for i in y1] # 非缺失比例

#plt.xlim(0,20)
plt.barh(x, y2, align="center", color="gray", label="非缺失")
plt.barh(x, y1, left=y2, color="red", label="缺失")
plt.legend()
plt.show()
```

    C:\Users\Tiny\AppData\Roaming\Python\Python36\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 38750 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    C:\Users\Tiny\AppData\Roaming\Python\Python36\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 32570 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    C:\Users\Tiny\AppData\Roaming\Python\Python36\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 22833 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    C:\Users\Tiny\AppData\Roaming\Python\Python36\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 38750 missing from current font.
      font.set_text(s, 0, flags=flags)
    C:\Users\Tiny\AppData\Roaming\Python\Python36\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 32570 missing from current font.
      font.set_text(s, 0, flags=flags)
    C:\Users\Tiny\AppData\Roaming\Python\Python36\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 22833 missing from current font.
      font.set_text(s, 0, flags=flags)
    


![png](output_23_1.png)



```python
df2[df2.isnull().sum(axis=1)>=3]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>carat</th>
      <th>cut</th>
      <th>color</th>
      <th>clarity</th>
      <th>depth</th>
      <th>table</th>
      <th>price</th>
      <th>x</th>
      <th>y</th>
      <th>z</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>




```python
nrow,ncol = df2.shape  # 找出行数 nrow
df2.loc[:,df2.isnull().sum(axis=0) >= 0.25 * nrow]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
    </tr>
    <tr>
      <th>2</th>
    </tr>
    <tr>
      <th>3</th>
    </tr>
    <tr>
      <th>4</th>
    </tr>
    <tr>
      <th>5</th>
    </tr>
    <tr>
      <th>6</th>
    </tr>
    <tr>
      <th>7</th>
    </tr>
    <tr>
      <th>8</th>
    </tr>
    <tr>
      <th>9</th>
    </tr>
    <tr>
      <th>10</th>
    </tr>
    <tr>
      <th>11</th>
    </tr>
    <tr>
      <th>12</th>
    </tr>
    <tr>
      <th>13</th>
    </tr>
    <tr>
      <th>14</th>
    </tr>
    <tr>
      <th>15</th>
    </tr>
    <tr>
      <th>16</th>
    </tr>
    <tr>
      <th>17</th>
    </tr>
    <tr>
      <th>18</th>
    </tr>
    <tr>
      <th>19</th>
    </tr>
    <tr>
      <th>20</th>
    </tr>
    <tr>
      <th>21</th>
    </tr>
    <tr>
      <th>22</th>
    </tr>
    <tr>
      <th>23</th>
    </tr>
    <tr>
      <th>24</th>
    </tr>
    <tr>
      <th>25</th>
    </tr>
    <tr>
      <th>26</th>
    </tr>
    <tr>
      <th>27</th>
    </tr>
    <tr>
      <th>28</th>
    </tr>
    <tr>
      <th>29</th>
    </tr>
    <tr>
      <th>30</th>
    </tr>
    <tr>
      <th>...</th>
    </tr>
    <tr>
      <th>53911</th>
    </tr>
    <tr>
      <th>53912</th>
    </tr>
    <tr>
      <th>53913</th>
    </tr>
    <tr>
      <th>53914</th>
    </tr>
    <tr>
      <th>53915</th>
    </tr>
    <tr>
      <th>53916</th>
    </tr>
    <tr>
      <th>53917</th>
    </tr>
    <tr>
      <th>53918</th>
    </tr>
    <tr>
      <th>53919</th>
    </tr>
    <tr>
      <th>53920</th>
    </tr>
    <tr>
      <th>53921</th>
    </tr>
    <tr>
      <th>53922</th>
    </tr>
    <tr>
      <th>53923</th>
    </tr>
    <tr>
      <th>53924</th>
    </tr>
    <tr>
      <th>53925</th>
    </tr>
    <tr>
      <th>53926</th>
    </tr>
    <tr>
      <th>53927</th>
    </tr>
    <tr>
      <th>53928</th>
    </tr>
    <tr>
      <th>53929</th>
    </tr>
    <tr>
      <th>53930</th>
    </tr>
    <tr>
      <th>53931</th>
    </tr>
    <tr>
      <th>53932</th>
    </tr>
    <tr>
      <th>53933</th>
    </tr>
    <tr>
      <th>53934</th>
    </tr>
    <tr>
      <th>53935</th>
    </tr>
    <tr>
      <th>53936</th>
    </tr>
    <tr>
      <th>53937</th>
    </tr>
    <tr>
      <th>53938</th>
    </tr>
    <tr>
      <th>53939</th>
    </tr>
    <tr>
      <th>53940</th>
    </tr>
  </tbody>
</table>
<p>53940 rows × 0 columns</p>
</div>



缺失值填充（一些常见方法及代码https://blog.csdn.net/qq_41780234/article/details/103306928 ）


```python
df_fill = df2.copy()
# df2['x']列的平均值 = fill
fill = df2['x'].median(skipna=True)# skipna 当数据集中存在 NA 值时，这些值会被简单跳过，除非整个切片（行或列）全是 NA
df_fill['x'] = df2['x'].fillna(fill)

fill = df2['cut'].mode()
print(f'填充值{fill}')
df_fill['cut'] = df2['cut'].fillna(fill)
```

    填充值0    Ideal
    Name: cut, dtype: category
    Categories (5, object): [Ideal < Premium < Good < Very Good < Fair]
    

分类型变量通过one-hot编码


```python
df3 = pd.get_dummies(data=df2,columns=['cut','color','clarity'])
print(df3.head())
```

       carat  depth  table  price     x     y     z  cut_Ideal  cut_Premium  \
    1   0.23   61.5   55.0    326  3.95  3.98  2.43          1            0   
    2   0.21   59.8   61.0    326  3.89  3.84  2.31          0            1   
    3   0.23   56.9   65.0    327  4.05  4.07  2.31          0            0   
    4   0.29   62.4   58.0    334  4.20  4.23  2.63          0            1   
    5   0.31   63.3   58.0    335  4.34  4.35  2.75          0            0   
    
       cut_Good     ...      color_I  color_J  clarity_IF  clarity_VVS1  \
    1         0     ...            0        0           0             0   
    2         0     ...            0        0           0             0   
    3         1     ...            0        0           0             0   
    4         0     ...            1        0           0             0   
    5         1     ...            0        1           0             0   
    
       clarity_VVS2  clarity_VS1  clarity_VS2  clarity_SI1  clarity_SI2  \
    1             0            0            0            0            1   
    2             0            0            0            1            0   
    3             0            1            0            0            0   
    4             0            0            1            0            0   
    5             0            0            0            0            1   
    
       clarity_I1  
    1           0  
    2           0  
    3           0  
    4           0  
    5           0  
    
    [5 rows x 27 columns]
    

## 5.数据划分（归一化）

将原数据中的X和Y拆分开来


```python
X = df3.drop('price',axis=1).values#.reshape()
Y = df3[['price']].values
print(f'自变量矩阵形状：{X.shape}')
print(f'因变量矩阵形状：{Y.shape}')
print(f'X[0] = {X[0]}') # 打印第0行看一下
print(f'Y[0] = {Y[0]}')
```

    自变量矩阵形状：(53940, 26)
    因变量矩阵形状：(53940, 1)
    X[0] = [ 0.23 61.5  55.    3.95  3.98  2.43  1.    0.    0.    0.    0.    0.
      1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      1.    0.  ]
    Y[0] = [326]
    

将数据集划分为=tv(训练集+验证集)+test测试集 8:2


```python
from sklearn.model_selection import ShuffleSplit
seed = 3
rs = ShuffleSplit(n_splits=1,test_size=0.2,random_state=seed)# n_splits表示生成几折
tv_id,test_id = next(rs.split(X))# 返回迭代器的下一个项目
print(f't+v 长度：{len(tv_id)}, test 长度：{len(test_id)}')
tvX,tvY = X[tv_id],Y[tv_id]
testX,testY = X[test_id],Y[test_id]
```

    t+v 长度：43152, test 长度：10788
    

tv(训练集+验证集)划分为=t训练集+v验证集 7:3


```python
rs2 =  ShuffleSplit(n_splits=1,test_size=0.3,random_state=seed)
train_id,val_id = next(rs2.split(tvX))
print(f't+v 长度：{len(train_id)}, test 长度：{len(val_id)}')
tX,tY = tvX[train_id],tvY[train_id]
vX,vY = tvX[val_id],tvY[val_id]
```

    t+v 长度：30206, test 长度：12946
    

归一化：把训练集中的每个变量变成 0 到 1 之间的数字


```python
import numpy as np
def fitAndTransform(train,validation):
    from sklearn.preprocessing import MinMaxScaler
    scaler = MinMaxScaler()
    scaler.fit(train)# 我们只用训练集的数据来学习，避免把验证集的信息透露给模型
    tScaler = scaler.transform(train)
    vScaler = scaler.transform(validation)
    print(f'缩放后的训练集train: min {np.min(tScaler)}, max {np.max(tScaler)}')
    print(f'缩放后的验证集validation: min {np.min(vScaler)}, max {np.max(vScaler)}')
    return tScaler,vScaler,scaler
```


```python
print('scale X--------')
tsX,vsX,scaler_X = fitAndTransform(tX,vX)
print('scale Y--------')
tsY,vsY,scaler_Y = fitAndTransform(tY,vY)
print(f'scaler_Y: min = {scaler_Y.data_min_}, data_range = {scaler_Y.data_range_}')
print(f'e.g tY={tY[0,0]} Scaler->  tsY{tsY[0,0]}')
```

    scale X--------
    缩放后的训练集train: min 0.0, max 1.0
    缩放后的验证集validation: min 0.0, max 1.0
    scale Y--------
    缩放后的训练集train: min 0.0, max 1.0
    缩放后的验证集validation: min 5.407743889249486e-05, max 1.0002703871944625
    scaler_Y: min = [326.], data_range = [18492.]
    e.g tY=1574 Scaler->  tsY0.06748864373783259
    

把 numpy 矩阵转成 torch 张量


```python
!pip install torch
```

    Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
    Collecting torch
      Downloading https://pypi.tuna.tsinghua.edu.cn/packages/60/fa/debcf7dcebf446f6ae6ec89177787adefaa1a828027873d961116d9e18f5/torch-1.7.1-cp36-cp36m-win_amd64.whl (184.1MB)
    Collecting dataclasses; python_version < "3.7" (from torch)
      Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl
    Collecting typing-extensions (from torch)
      Downloading https://pypi.tuna.tsinghua.edu.cn/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl
    Requirement already satisfied: numpy in c:\programdata\anaconda3\lib\site-packages (from torch) (1.15.4)
    Installing collected packages: dataclasses, typing-extensions, torch
    Successfully installed dataclasses-0.8 torch-1.7.1 typing-extensions-3.7.4.3
    

    arviz 0.6.1 requires netcdf4, which is not installed.
    arviz 0.6.1 requires xarray>=0.11, which is not installed.
    distributed 1.21.8 requires msgpack, which is not installed.
    google-auth 1.11.0 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.
    pytest 3.5.1 has requirement pluggy<0.7,>=0.5, but you'll have pluggy 0.13.1 which is incompatible.
    cryptography 3.3.1 has requirement cffi>=1.12, but you'll have cffi 1.11.5 which is incompatible.
    You are using pip version 10.0.1, however version 21.0.1 is available.
    You should consider upgrading via the 'python -m pip install --upgrade pip' command.
    


```python
import torch as t
tstX = t.tensor(tsX).float()
tstY = t.tensor(tsY).float()
vstX = t.tensor(vsX).float()
vstY = t.tensor(vsY).float()
N,p = tstX.shape
print(f'训练数据共{N}条，自变量个数{p}个')
```

    训练数据共30206条，自变量个数26个
    

tstX,tstY,vstX,vstY,testX,testY存为变量


```python
import pickle
variables = [tstX,tstY,vstX,vstY,testX,testY]
variablesNames = ['tstX','tstY','vstX','vstY','testX','testY']
lastPath = r'C:\Users\Tiny\0_jupyter_notebook\基础\202102机器学习\完整版0208\05. 神经网络训练与模型调优\data'

for i in range(len(variablesNames)):
    filename = lastPath+ '\\' + variablesNames[i] + '.data'
    with open(filename, 'wb') as f:
        pickle.dump(variables[i], f)
```

将保存的变量重新读入


```python
import os
```


```python
variablesNames = os.listdir(lastPath)
variablesDic = dict()
for i in range(len(variablesNames)):
    filename = lastPath+ '\\' + variablesNames[i]
    with open(filename, 'rb') as f:
         variablesDic[variablesNames[i]] = pickle.load(f)
```


```python
variablesDic
```




    {'testX.data': array([[ 0.4 , 62.  , 56.  , ...,  0.  ,  0.  ,  0.  ],
            [ 1.61, 63.8 , 58.  , ...,  0.  ,  0.  ,  0.  ],
            [ 1.02, 62.5 , 57.  , ...,  0.  ,  0.  ,  0.  ],
            ...,
            [ 0.25, 59.3 , 59.  , ...,  0.  ,  0.  ,  0.  ],
            [ 0.32, 61.8 , 56.  , ...,  0.  ,  0.  ,  0.  ],
            [ 1.51, 63.  , 57.  , ...,  0.  ,  0.  ,  0.  ]]),
     'testY.data': array([[ 951],
            [9467],
            [8162],
            ...,
            [ 548],
            [1067],
            [7455]], dtype=int64),
     'tstX.data': tensor([[0.0644, 0.5361, 0.3269,  ..., 0.0000, 0.0000, 0.0000],
             [0.0249, 0.5250, 0.2692,  ..., 1.0000, 0.0000, 0.0000],
             [0.0437, 0.5278, 0.2692,  ..., 0.0000, 0.0000, 0.0000],
             ...,
             [0.0208, 0.5278, 0.2308,  ..., 0.0000, 0.0000, 0.0000],
             [0.0624, 0.6333, 0.2692,  ..., 0.0000, 0.0000, 0.0000],
             [0.1143, 0.4861, 0.2885,  ..., 0.0000, 1.0000, 0.0000]]),
     'tstY.data': tensor([[0.0675],
             [0.0233],
             [0.0407],
             ...,
             [0.0243],
             [0.0554],
             [0.1118]]),
     'vstX.data': tensor([[0.0229, 0.5611, 0.2500,  ..., 0.0000, 0.0000, 0.0000],
             [0.2079, 0.5361, 0.3077,  ..., 0.0000, 1.0000, 0.0000],
             [0.1081, 0.5056, 0.2115,  ..., 0.0000, 1.0000, 0.0000],
             ...,
             [0.2183, 0.4444, 0.3462,  ..., 0.0000, 1.0000, 0.0000],
             [0.1247, 0.5389, 0.2692,  ..., 1.0000, 0.0000, 0.0000],
             [0.2162, 0.5472, 0.3077,  ..., 0.0000, 1.0000, 0.0000]]),
     'vstY.data': tensor([[0.0162],
             [0.2985],
             [0.1133],
             ...,
             [0.3086],
             [0.1204],
             [0.2477]])}


